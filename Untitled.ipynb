{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09472bfb-2223-4f83-8f98-5a48d29dd89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_name=<Table.orders: 'orders'> columns=[<Column.id: 'id'>, <Column.expected_delivery_date: 'expected_delivery_date'>, <Column.delivered_at: 'delivered_at'>] conditions=[Condition(column='status', operator=<Operator.eq: '='>, value='fulfilled'), Condition(column='ordered_at', operator=<Operator.ge: '>='>, value='2023-05-01'), Condition(column='ordered_at', operator=<Operator.le: '<='>, value='2023-05-31'), Condition(column='delivered_at', operator=<Operator.gt: '>'>, value=DynamicValue(column_name='expected_delivery_date'))] order_by=<OrderBy.asc: 'asc'>\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import Union\n",
    "\n",
    "from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = OpenAI()\n",
    "client = wrap_openai(client)\n",
    "\n",
    "\n",
    "class Table(str, Enum):\n",
    "    orders = \"orders\"\n",
    "    customers = \"customers\"\n",
    "    products = \"products\"\n",
    "\n",
    "\n",
    "class Column(str, Enum):\n",
    "    id = \"id\"\n",
    "    status = \"status\"\n",
    "    expected_delivery_date = \"expected_delivery_date\"\n",
    "    delivered_at = \"delivered_at\"\n",
    "    shipped_at = \"shipped_at\"\n",
    "    ordered_at = \"ordered_at\"\n",
    "    canceled_at = \"canceled_at\"\n",
    "\n",
    "\n",
    "class Operator(str, Enum):\n",
    "    eq = \"=\"\n",
    "    gt = \">\"\n",
    "    lt = \"<\"\n",
    "    le = \"<=\"\n",
    "    ge = \">=\"\n",
    "    ne = \"!=\"\n",
    "\n",
    "\n",
    "class OrderBy(str, Enum):\n",
    "    asc = \"asc\"\n",
    "    desc = \"desc\"\n",
    "\n",
    "\n",
    "class DynamicValue(BaseModel):\n",
    "    column_name: str\n",
    "\n",
    "\n",
    "class Condition(BaseModel):\n",
    "    column: str\n",
    "    operator: Operator\n",
    "    value: Union[str, int, DynamicValue]\n",
    "\n",
    "\n",
    "class Query(BaseModel):\n",
    "    table_name: Table\n",
    "    columns: list[Column]\n",
    "    conditions: list[Condition]\n",
    "    order_by: OrderBy\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant. The current date is August 6, 2024. You help users query for the data they are looking for by calling the query function.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"look up all my orders in may of last year that were fulfilled but not delivered on time\",\n",
    "        },\n",
    "    ],\n",
    "    tools=[\n",
    "        openai.pydantic_function_tool(Query),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.tool_calls[0].function.parsed_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6903df-d580-4988-a412-29acbe5a997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import ell\n",
    "\n",
    "\n",
    "@ell.simple(model=\"gpt-4o-mini\", temperature=1.0, n=10)\n",
    "def write_ten_drafts(idea: str):\n",
    "    \"\"\"You are an adept story writer. The story should only be 3 paragraphs\"\"\"\n",
    "    return f\"Write a story about {idea}.\"\n",
    "\n",
    "\n",
    "@ell.simple(model=\"gpt-4o\", temperature=0.1)\n",
    "def choose_the_best_draft(drafts: List[str]):\n",
    "    \"\"\"You are an expert fiction editor.\"\"\"\n",
    "    return f\"Choose the best draft from the following list: {'\\n'.join(drafts)}.\"\n",
    "\n",
    "\n",
    "drafts = write_ten_drafts(idea)\n",
    "\n",
    "best_draft = choose_the_best_draft(drafts)  # Best of 10 sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc5e407-5498-417d-8643-b049eef0af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6791557-dfdd-489c-a8c7-7f1884cd9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple(**dec_kwargs):\n",
    "    def decorator(fn):\n",
    "        model, msgs = (\n",
    "            init_chat_model(**dec_kwargs),\n",
    "            [(\"system\", getattr(fn, \"__doc__\"))] if getattr(fn, \"__doc__\") else [],\n",
    "        )\n",
    "\n",
    "        def call(*args, **kwargs):\n",
    "            return model.invoke([*msgs, (\"user\", str(fn(*args, **kwargs)))]).content\n",
    "\n",
    "        return call\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20961e-1715-4d80-a231-abcd61dccece",
   "metadata": {},
   "outputs": [],
   "source": [
    "@simple(model=\"gpt-4o-mini\", temperature=1.0, n=10)\n",
    "def write_ten_drafts(idea: str):\n",
    "    \"\"\"You are an adept story writer. The story should only be 3 paragraphs\"\"\"\n",
    "    return f\"Write a story about {idea}.\"\n",
    "\n",
    "\n",
    "@simple(model=\"gpt-4o-mini\")\n",
    "def choose_the_best_draft(drafts: list[str]):\n",
    "    \"\"\"You are an expert fiction editor.\"\"\"\n",
    "    return f\"Choose the best draft from the following list: {drafts}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cb3f496-4054-4081-b7ca-039f80b34557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# def _get_inputs(signature, *args, **kwargs):\n",
    "#     \"\"\"Return a dictionary of inputs from the function signature.\"\"\"\n",
    "#     bound = signature.bind_partial(*args, **kwargs)\n",
    "#     bound.apply_defaults()\n",
    "#     arguments = dict(bound.arguments)\n",
    "#     arguments.pop(\"self\", None)\n",
    "#     arguments.pop(\"cls\", None)\n",
    "#     for param_name, param in signature.parameters.items():\n",
    "#         if param.kind == inspect.Parameter.VAR_KEYWORD:\n",
    "#             # Update with the **kwargs, and remove the original entry\n",
    "#             # This is to help flatten out keyword arguments\n",
    "#             if param_name in arguments:\n",
    "#                 arguments.update(arguments[param_name])\n",
    "#                 arguments.pop(param_name)\n",
    "\n",
    "#     return arguments\n",
    "\n",
    "\n",
    "# def _get_inputs_safe(signature, *args, **kwargs):\n",
    "#     try:\n",
    "#         return _get_inputs(signature, *args, **kwargs)\n",
    "#     except BaseException as e:\n",
    "#         print(e)\n",
    "#         return {\"args\": args, \"kwargs\": kwargs}\n",
    "\n",
    "\n",
    "def simple(**dec_kwargs):\n",
    "    def decorator(fn):\n",
    "        sysprompt = getattr(fn, \"__doc__\", \"\")\n",
    "        # sig = inspect.signature(fn)\n",
    "        model = init_chat_model(**dec_kwargs)\n",
    "        # agent = create_react_agent(model, [fn])\n",
    "\n",
    "        def call(*args, **kwargs):\n",
    "            # agent_args = _get_inputs_safe(sig, *args, **kwargs)\n",
    "            resp = fn(*args, **kwargs)\n",
    "            return model.invoke([(\"system\", sysprompt), (\"user\", str(resp))]).content\n",
    "\n",
    "        return call\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24ef9043-ff1a-4454-9e6d-c86a2655e2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32a36963-4cd0-476f-903a-064cea9330eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bed51da2-a920-4971-bbae-d84ce99cf884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The phrase \"once upon a time\" is the better draft. It evokes a sense of storytelling and invites the reader into a narrative, while \"I like pie\" is more of a simple statement without much context or depth. \"Once upon a time\" has the potential to lead into a rich and engaging story.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56237a71-3446-43d5-bb2e-6cbc0ddf7364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
